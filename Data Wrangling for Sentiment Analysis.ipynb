{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acbd5aab-762d-4497-b223-aa4a5e0157db",
   "metadata": {},
   "source": [
    "Sentiment analysis is a powerful technique for understanding the emotions conveyed in text. By interpreting these emotions, businesses and organizations can gain valuable insights into public opinion, enabling them to make informed decisions that drive growth. This analysis provides real feedback from the public, helping organizations take necessary actions based on genuine sentiments.\n",
    "\n",
    "I have developed a sentiment analysis model designed to help people understand the sentiment behind various texts. This model has been trained on diverse datasets, including the IMDB dataset and Hotel dataset and ensuring its ability to accurately interpret emotions from different sources of text.\n",
    "\n",
    "To achieve this, a Large Language Model (LLM) was utilized and fine-tuned on these datasets. In the field of AI, one of the greatest advancements has been the development of transformers, which are designed to understand natural language with exceptional efficiency and accuracy. By incorporating this technique into my analysis, the model can accurately understand, interpret, and predict sentiments from text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd612e5b-3ad4-47da-b5e1-1d9a30d462f0",
   "metadata": {},
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327392b5-4fda-4a72-9141-cc412d3ca2a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate transformers peft datasets trl BitsandBytes torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c223145-2d10-4f0e-81b2-b0d838306b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall bitsandbytes\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f9b0b3-2b4d-4486-90d4-0cbef1751dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, DistilBertForSequenceClassification, BitsAndBytesConfig\n",
    "from warnings import filterwarnings\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig,TaskType\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ce19a-5c96-4855-888b-bd48fe420e32",
   "metadata": {},
   "source": [
    "## Loading Dataset for the Analysis\n",
    "\n",
    "Dataset has been downloaded from Standford.ai website which are IMDB reviews around 50,000. Also as this analysis is not only based on movie reviews i have downloaded the other reviews data and loaded loacally then uploaded in Jupyter notebook for further analysis. Data has been downloaded from multiple sources and then merged them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36992d4a-e64e-4b1f-a654-119c4e162343",
   "metadata": {},
   "source": [
    "##### STANFORD IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560ac970-2b47-4305-a578-de97ff51394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Abhinav Khandelwal\\\\Desktop\\\\Machine Learning\\\\LLM Projects\\\\Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011d855b-732d-4be3-8afa-433f590c7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "curdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be039bd5-c024-47ec-9c7f-2ba073e30bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Review = []\n",
    "Label = []\n",
    "\n",
    "for i in os.listdir():\n",
    "    dataset_dir = curdir + \"\\\\\" + os.listdir()[0]\n",
    "    data_dir = os.listdir(dataset_dir)\n",
    "    for j in data_dir:\n",
    "        t_data_dir = dataset_dir + \"\\\\\" + j\n",
    "        t_data = os.listdir(t_data_dir)\n",
    "        for k in t_data:\n",
    "            t_data2 = t_data_dir + \"\\\\\" + k\n",
    "            t_data3 = os.listdir(t_data2)\n",
    "            for q in t_data3:\n",
    "                label = t_data2[-3:]\n",
    "                file_dir = t_data2 + \"\\\\\" + q\n",
    "                with open(file_dir,encoding = \"utf-8\") as file:\n",
    "                    Review.append(file.read())\n",
    "                if label == \"pos\":\n",
    "                    Label.append(1)\n",
    "                else:\n",
    "                    Label.append(0)\n",
    "\n",
    "Review = pd.DataFrame(dict(Final_Review = Review,Sentiment = Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1beeffa1-d54e-460f-aa88-09254c130c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB = Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fbb6b067-6e3a-408a-83a7-e552aab29ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37776</th>\n",
       "      <td>This is the first out of the Guinea Pig series...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46302</th>\n",
       "      <td>A lot of the user comments i have seen on the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29747</th>\n",
       "      <td>I was very excited about this film when I firs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Final_Review  Sentiment\n",
       "37776  This is the first out of the Guinea Pig series...          1\n",
       "46302  A lot of the user comments i have seen on the ...          1\n",
       "29747  I was very excited about this film when I firs...          0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50a956-1ae5-4139-b1df-10ceefc8ca1d",
   "metadata": {},
   "source": [
    "#### Hotel Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d4a82517-567d-4b4d-80f7-57989e28b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in os.listdir():\n",
    "    hotel_dir = os.getcwd() + \"\\\\\" + i\n",
    "    hotel_t_data = os.listdir(hotel_dir)\n",
    "    for o in hotel_t_data:\n",
    "        hotel_data = hotel_dir + \"\\\\\" + o\n",
    "        hotel_1 = pd.read_csv(hotel_data)\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "36bd778c-0409-4e9d-9516-274313cfe2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_2 = pd.read_csv(\"C:\\\\Users\\\\Abhinav Khandelwal\\\\Desktop\\\\Machine Learning\\\\LLM Projects\\\\Sentiment Analysis\\\\tripadvisor_hotel_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9681849-4d84-46d7-95b5-7066b03bdf30",
   "metadata": {},
   "source": [
    " ### Data Preprocessing, Data Cleaning and EDA\n",
    "\n",
    "For the analysis i have downloaded dataset of hotels which have ranking from 0 - 5 i will encode these into 1 and 0. Any review less than equal to 2 will be 0 and any review greater than and equal to 3 will be 1. \n",
    "In the hotel dataset there are unnecessary columns which i will remove.\n",
    "There are imbalancing in the dataset so i will remove the majority data as i have enough data for the analysis (more than 70,000 data points).\n",
    "There will be some preprocessing like tags removal and punctuation removal. I will keep the stop words i think it will enhance my analysis and i am using LLM models and they are able to understand the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29449a4b-b5d1-475a-bfc2-bc3c8fb4db42",
   "metadata": {},
   "source": [
    "**Removing unncessary columns from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7cd75b56-3996-4f33-833e-2e62dd0babe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_1 = hotel_1[[\"Description\",\"Is_Response\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba831b-5419-4c6e-b05d-e9c36f7e84b9",
   "metadata": {},
   "source": [
    "**Encoding ratings into Sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "59d10e18-1a82-4aa3-b77d-80a387e3157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_2[\"Rating\"] = hotel_2[\"Rating\"].apply(lambda x: 1 if x >=3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "28db09cd-ccde-4b12-bbb2-440e0cbdd06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16391</th>\n",
       "      <td>okay decor nice new, desk staff uppity profess...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>just ok overall impression property customer s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>okay just got riu south beach miami, stayed 2 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Rating\n",
       "16391  okay decor nice new, desk staff uppity profess...       1\n",
       "4169   just ok overall impression property customer s...       1\n",
       "6293   okay just got riu south beach miami, stayed 2 ...       0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_2.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bf0d2e80-f415-4544-8b79-7e019d4b8aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hotel_1[\"Is_Response\"] = hotel_1[\"Is_Response\"].apply(lambda x: 1 if x == \"happy\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4e172ae5-5051-4208-9de3-42ef415c6d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18614</th>\n",
       "      <td>DO NOT STAY HERE!!! my boyfriend and I figured...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30066</th>\n",
       "      <td>This was a great hotel for our family of four....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20350</th>\n",
       "      <td>Seriously - this place is great. We (two adult...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description  Is_Response\n",
       "18614  DO NOT STAY HERE!!! my boyfriend and I figured...            0\n",
       "30066  This was a great hotel for our family of four....            1\n",
       "20350  Seriously - this place is great. We (two adult...            1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_1.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9281d2-fa4f-4104-8116-de00be723409",
   "metadata": {},
   "source": [
    "**Changing the column names and make it uniform for the merging.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3d2bf459-7dd2-48dd-8544-7d27b1eaf34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB.columns = [\"Reviews\",\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ebc16de7-da4d-4648-91c7-c79e6854b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_1.columns = [\"Reviews\",\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0cc82ec2-31c5-49b9-807d-0719fe9b1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_2.columns = [\"Reviews\",\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293d70d-c0c0-4e0a-a6b4-5bba365a58c4",
   "metadata": {},
   "source": [
    "**Merge all the datasets to form 1 dataset for the analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2adac393-10f8-45a6-82ed-161a9cd8e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data = pd.concat([IMDB,hotel_1,hotel_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b346b-4f81-4845-97c0-a4a7f85d1c29",
   "metadata": {},
   "source": [
    "**Now Exploratory Data Analysis will be done to understand the pattern of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "da31cf85-f091-4aab-a13e-cdb51989bc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109423, 2)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "09f75872-05b8-40b8-bc1e-70f27c347578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    62.873436\n",
       "0    37.126564\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking whether the data is balanced or not. We can see clearly that our data is not balanced so we can go for some balancing technique like augmentation\n",
    "#class_weights but we have enough data for our analysis from the above we can see that we have more than 1,00,000 data points so for the uniformity\n",
    "#i will remove the majority data points. In our case i will remove positive labeled points\n",
    "\n",
    "Final_data[\"Sentiment\"].value_counts()/Final_data.shape[0] * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "712515cf-c70b-4f1a-8d2e-cf0eb2d005b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the data to avoid any kind of biasness.\n",
    "Shuffled_data = Final_data.sample(frac=1,random_state=43,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "75cc936f-4131-4b8a-9e8d-6e722608ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we will filtered the positive labeled data and reduce it to 40625 currently we have 68798 we will use sampling way to extract the data.\n",
    "\n",
    "positive = Shuffled_data[Shuffled_data[\"Sentiment\"]==1].sample(40625,ignore_index=True,random_state=44)\n",
    "negative = Shuffled_data[Shuffled_data[\"Sentiment\"]==0]\n",
    "Dataset = pd.concat([positive,negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "34783ea8-e230-4fb0-a3a5-7e6c7ded4b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    40625\n",
       "0    40625\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we have balanced data.\n",
    "Dataset[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "5d58ec26-8f89-42ca-8a82-6fe4b6af6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index\n",
    "Dataset.reset_index(inplace=True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "0515cc4f-39f5-49d5-8780-15a9e20dfb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81250 entries, 0 to 81249\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Reviews    81250 non-null  object\n",
      " 1   Sentiment  81250 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Datatyes are correct and we don't have any null values as well\n",
    "Dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "39376093-9f4e-4757-ab87-a360d53a3ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>Wow! So much fun! Probably a bit much for norm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14808</th>\n",
       "      <td>If you want Scream or anything like the big-st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14842</th>\n",
       "      <td>A longtime fan of Bette Midler, I must say her...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15652</th>\n",
       "      <td>The undoubted highlight of this movie is Peter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15765</th>\n",
       "      <td>This is a new Barbie movie. The graphics were ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80814</th>\n",
       "      <td>I found it hard to care about these characters...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80989</th>\n",
       "      <td>\"Three\" is a seriously dumb shipwreck movie. M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81071</th>\n",
       "      <td>I do not fail to recognize Haneke's above-aver...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81159</th>\n",
       "      <td>Les Visiteurs, the first movie about the medie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81173</th>\n",
       "      <td>Wow, this film was terrible. It is as simple a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Reviews  Sentiment\n",
       "5522   Wow! So much fun! Probably a bit much for norm...          1\n",
       "14808  If you want Scream or anything like the big-st...          1\n",
       "14842  A longtime fan of Bette Midler, I must say her...          1\n",
       "15652  The undoubted highlight of this movie is Peter...          1\n",
       "15765  This is a new Barbie movie. The graphics were ...          1\n",
       "...                                                  ...        ...\n",
       "80814  I found it hard to care about these characters...          0\n",
       "80989  \"Three\" is a seriously dumb shipwreck movie. M...          0\n",
       "81071  I do not fail to recognize Haneke's above-aver...          0\n",
       "81159  Les Visiteurs, the first movie about the medie...          0\n",
       "81173  Wow, this film was terrible. It is as simple a...          0\n",
       "\n",
       "[346 rows x 2 columns]"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking duplicated rows. We can see that pandas is showing 349 datasets as duplicated but if we see the data there is no duplication. \n",
    "#But on the safer side we will remove these duplicates.\n",
    "Dataset[Dataset.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "1e94d704-8b21-4d8d-bbaf-2d166353a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing Duplicates\n",
    "Dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "ed569b8b-d542-484e-bfda-e9c0d04d1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CAUTION: Potential Spoilers Ahead!<br /><br />\"Steven Spielberg Presents Tiny Toon Adventures\" was always one of my favorite cartoons growing up (heck, it still is). And this movie perfectly captures everything I love about the show and puts it in full-length form.<br /><br />Beautifully animated by the Tokyo Movie Shinsa studio (WB outsourced every \"Tiny Toons\" project, and this was the best studio to handle the show), the movie starts at the end of the school year at Acme Looniversity, the renowned cartoon college where Buster and Babs Bunny (no relation) and their teenage toon peers learn from the masters of animated lunacy, the Looney Tunes. After the final bell, the movie splits off into five different plots. Buster engages Babs in a water gun fight that culminates with a bursting dam and a tidal wave, sending Buster, Babs, and Elmyra\\'s dog Byron downriver on an overturned picnic table in search of adventure in the deep South. Plucky Duck talks Hamton Pig and his family into letting him come with them to HappyWorldLand, \"The Happiest Place in the Western Hemisphere\", but he has to put up with an excruciating car ride and the threat of a chainsaw-wielding hitchhiker. Elmyra\\'s cat Furball finally runs away, but she isn\\'t daunted...not when there are plenty of \"aminals\" to play with at the Acme Safari Park. Fifi la Fume devotes her summer to hunting down her heartthrob, movie star Johnny Pew, in the hopes of getting an autograph. Of course, the hotel he\\'s staying at is nearly impenetrable. And Shirley McLoon sets up a fortune telling booth on the Acme Acres Boardwalk...and lets her guard down on her day off when Fowlmouth takes her to see the horror flick \"Skunkophobia\".<br /><br />All these story lines are sidesplittingly hilarious, and some of them even overlap in the end. The only complaint I have with this movie is that it doesn\\'t make full use of the Tiny Toons roster - Dizzy Devil and Mary Melodie have only one scene, Gogo Dodo only appears at the beginning and end of the film, and Montana Max, Sweetie, Calamity Coyote, and Little Beeper are nowhere to be found. Still, they\\'re excusable flaws in an otherwise perfect film. This movie is pretty rare today, since it\\'s over 12 years old and has never been released on DVD to my knowledge, but I highly suggest you track it down - anyone who\\'s a fan of Warner Bros. animation, either classic or contemporary, NEEDS to see this movie.'"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.Reviews[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "cf7290eb-a5e2-48b3-815f-ac6a9aac5c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CAUTION: Potential Spoilers Ahead!\"Steven Spielberg Presents Tiny Toon Adventures\" was always one of my favorite cartoons growing up (heck, it still is). And this movie perfectly captures everything I love about the show and puts it in full-length form.Beautifully animated by the Tokyo Movie Shinsa studio (WB outsourced every \"Tiny Toons\" project, and this was the best studio to handle the show), the movie starts at the end of the school year at Acme Looniversity, the renowned cartoon college where Buster and Babs Bunny (no relation) and their teenage toon peers learn from the masters of animated lunacy, the Looney Tunes. After the final bell, the movie splits off into five different plots. Buster engages Babs in a water gun fight that culminates with a bursting dam and a tidal wave, sending Buster, Babs, and Elmyra\\'s dog Byron downriver on an overturned picnic table in search of adventure in the deep South. Plucky Duck talks Hamton Pig and his family into letting him come with them to HappyWorldLand, \"The Happiest Place in the Western Hemisphere\", but he has to put up with an excruciating car ride and the threat of a chainsaw-wielding hitchhiker. Elmyra\\'s cat Furball finally runs away, but she isn\\'t daunted...not when there are plenty of \"aminals\" to play with at the Acme Safari Park. Fifi la Fume devotes her summer to hunting down her heartthrob, movie star Johnny Pew, in the hopes of getting an autograph. Of course, the hotel he\\'s staying at is nearly impenetrable. And Shirley McLoon sets up a fortune telling booth on the Acme Acres Boardwalk...and lets her guard down on her day off when Fowlmouth takes her to see the horror flick \"Skunkophobia\".All these story lines are sidesplittingly hilarious, and some of them even overlap in the end. The only complaint I have with this movie is that it doesn\\'t make full use of the Tiny Toons roster - Dizzy Devil and Mary Melodie have only one scene, Gogo Dodo only appears at the beginning and end of the film, and Montana Max, Sweetie, Calamity Coyote, and Little Beeper are nowhere to be found. Still, they\\'re excusable flaws in an otherwise perfect film. This movie is pretty rare today, since it\\'s over 12 years old and has never been released on DVD to my knowledge, but I highly suggest you track it down - anyone who\\'s a fan of Warner Bros. animation, either classic or contemporary, NEEDS to see this movie.'"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove html tags.\n",
    "Dataset[\"Reviews\"] = Dataset[\"Reviews\"].str.replace(\"<.+?>\",\"\",regex=True)\n",
    "Dataset[\"Reviews\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "cc5d6195-c870-4d36-9f2e-4f131b4d6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Making all the letters in lower_case for uniformity\n",
    "Dataset[\"Reviews\"] = Dataset[\"Reviews\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "955ce2c9-252d-4a2a-8cf1-5e531d0e8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function for removing punctuations\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans(\" \",\" \",string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "6f5cde9a-4ff4-4060-a3ed-7eacae66a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Punctuations\n",
    "Dataset[\"Reviews\"] = Dataset[\"Reviews\"].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "d72fa692-d162-4858-a9df-4e5edf3fcf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we loved every second of our new years eve getaway from the moment we arrived until we had to fly home service was impeccable and the suite was everything we couldve asked for and then some enjoyed a massage to start off the new year right and i loved the relaxation room in the spa  the beds are so comfortable that i almost fell asleep the staff went out of their way and accommodated our friends with a toddler and provided a crib complete with stuffed animal to make the little one happy\\nthe hotel was kind enough to send us chocolates and fruit as a small holiday gift which was a nice touch and we did enjoy them along with some champagne i miss the plush robes the mood lighting and the tub in the executive suitei would most definitely stay again when i return to chicago in fact i cant wait to go back'"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have removed punctuations but there is a new line symbol (\\n) still there which we will remove through regex\n",
    "Dataset[\"Reviews\"][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "490137d7-6bf8-4ee1-842c-7ab981d5aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing (\\n) tags\n",
    "Dataset[\"Reviews\"] = Dataset[\"Reviews\"].str.replace(r'\\n','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "425bbee0-e613-4939-a742-d29a98e18694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we loved every second of our new years eve getaway from the moment we arrived until we had to fly home service was impeccable and the suite was everything we couldve asked for and then some enjoyed a massage to start off the new year right and i loved the relaxation room in the spa  the beds are so comfortable that i almost fell asleep the staff went out of their way and accommodated our friends with a toddler and provided a crib complete with stuffed animal to make the little one happythe hotel was kind enough to send us chocolates and fruit as a small holiday gift which was a nice touch and we did enjoy them along with some champagne i miss the plush robes the mood lighting and the tub in the executive suitei would most definitely stay again when i return to chicago in fact i cant wait to go back'"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[\"Reviews\"][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "a347edc0-04a5-4e37-a2c4-fca33bfb4675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50.159448\n",
       "0    49.840552\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have our final dataset ready which we have preprocessed and it is balanced\n",
    "Dataset[\"Sentiment\"].value_counts()/Dataset.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ecc02356-52e6-4da4-8ed0-e4636f9d88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are done with Data Loading and Data Preprocessing. Now we will do the fine tuning our LLM model. I have checked hugging face for the models which \n",
    "#can be use for this purpose i decided Distilbert for the analysis there were 2 reasons first this Distilbert was pretrained on large corpus of the \n",
    "#data same as Bert and it has good understanding of general language and it has less parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c872ee6-b514-4f29-a8fc-7fd573104c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
